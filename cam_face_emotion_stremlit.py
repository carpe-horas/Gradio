# streamlit run cam_face_emotion_stremlit.py


import streamlit as st
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
import time

# ëª¨ë¸ ë¡œë“œ (ì‚¬ì „ í•™ìŠµëœ ê°ì • ë¶„ì„ ëª¨ë¸)
emotion_model_path = "./models/emotion_model_tf2.h5"
model = load_model(emotion_model_path)

# OpenCV ì–¼êµ´ ê°ì§€ê¸° ë¡œë“œ (ê²½ë¡œ ìˆ˜ì •)
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

# ê°ì • ë¦¬ìŠ¤íŠ¸ (FER2013 ê¸°ì¤€)
emotion_labels = ["Angry", "Disgust", "Fear", "Happy", "Neutral", "Sad", "Surprise"]

# ê°ì •ë³„ ë°°ê²½ ìƒ‰ìƒ ì„¤ì •
emotion_colors = {
    "Happy": "#90EE90",
    "Angry": "#FF4500",
    "Sad": "#4682B4",
    "Neutral": "#D3D3D3",
    "Surprise": "#FFD700",
    "Fear": "#800080",
    "Disgust": "#228B22"
}

# Streamlit UI
st.title("ğŸ­ ì‹¤ì‹œê°„ ì–¼êµ´ ê°ì • ë¶„ì„")
st.write("ì›¹ìº ì„ í†µí•´ ì–¼êµ´ ê°ì •ì„ ë¶„ì„í•˜ê³  í™”ë©´ì— í˜„ì¬ ê°ì •ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")

# ì›¹ìº  ìƒíƒœ ê´€ë¦¬ ë³€ìˆ˜ ì´ˆê¸°í™”
if "webcam_active" not in st.session_state:
    st.session_state["webcam_active"] = False
if "current_emotion" not in st.session_state:
    st.session_state["current_emotion"] = None  #  ì²˜ìŒì—” ê°ì • ìƒíƒœ ì—†ìŒ

# ê°ì • ìƒíƒœ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ê³µê°„ í™•ë³´
emotion_display = st.empty()

if st.session_state["current_emotion"] is None:
    emotion_display.markdown("### í˜„ì¬ ê°ì • ìƒíƒœ: -")  # ì›¹ìº  ì‹¤í–‰ ì „ì—ëŠ” "-"ë¡œ í‘œì‹œ
else:
    emotion_display.markdown(f"### í˜„ì¬ ê°ì • ìƒíƒœ: **{st.session_state['current_emotion']}**")


col1, col2 = st.columns([0.2, 0.8])

with col1:
    if st.button("ğŸ“· ì›¹ìº  ì‹¤í–‰"):
        st.session_state["webcam_active"] = True

with col2:
    if st.button("ğŸ›‘ ì›¹ìº  ë„ê¸°"):
        # ëª¨ë“  ìƒíƒœ ì´ˆê¸°í™” í›„ UI ìƒˆë¡œê³ ì¹¨
        st.session_state["webcam_active"] = False
        st.session_state["current_emotion"] = "Neutral"
        st.rerun()  # UI ì „ì²´ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ì¦‰ì‹œ ì¢…ë£Œ

# ê°ì •ë³„ ë°°ê²½ ìƒ‰ìƒ ë³€ê²½ í•¨ìˆ˜
def change_background_color(emotion):
    color = emotion_colors.get(emotion, "#FFFFFF")
    st.markdown(
        f"""
        <style>
        .stApp {{
            background-color: {color};
        }}
        </style>
        """,
        unsafe_allow_html=True
    )

# ì›¹ìº  í”„ë ˆì„ ì²˜ë¦¬ í•¨ìˆ˜
def detect_emotion(frame):
    if not st.session_state["webcam_active"]:  # ì›¹ìº ì´ ì¢…ë£Œëœ ê²½ìš° ì¦‰ì‹œ ë°˜í™˜
        return frame

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))

    for (x, y, w, h) in faces:
        if not st.session_state["webcam_active"]:  # ì˜ˆì¸¡ ì „ì— ë‹¤ì‹œ í•œ ë²ˆ ìƒíƒœ í™•ì¸
            return frame

        roi_gray = gray[y:y + h, x:x + w]
        roi_gray = cv2.resize(roi_gray, (64, 64))
        roi_gray = np.expand_dims(roi_gray, axis=-1)
        roi_gray = np.expand_dims(roi_gray, axis=0)
        roi_gray = roi_gray / 255.0

        if not st.session_state["webcam_active"]:  # ì˜ˆì¸¡ ì „ì— ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸
            return frame

        try:
            predictions = model.predict(roi_gray)  # ì›¹ìº ì´ êº¼ì§€ë©´ ì˜ˆì¸¡ ìˆ˜í–‰ X
            max_index = np.argmax(predictions)
            emotion = emotion_labels[max_index]
        except Exception as e:
            st.warning("ì›¹ìº ì´ êº¼ì§€ëŠ” ë„ì¤‘ ê°ì • ì˜ˆì¸¡ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            return frame  # ì˜ˆì¸¡ ì¤‘ ì—ëŸ¬ ë°œìƒ ì‹œ ì•ˆì „ ì¢…ë£Œ

        # ê°ì • ìƒíƒœ ì—…ë°ì´íŠ¸
        st.session_state["current_emotion"] = emotion
        emotion_display.markdown(f"### í˜„ì¬ ê°ì • ìƒíƒœ: **{st.session_state['current_emotion']}**")

        # ë°°ê²½ ìƒ‰ìƒ ë³€ê²½ ì ìš©
        change_background_color(emotion)

        # ê°ì •ì— ë§ëŠ” ë°•ìŠ¤ ìƒ‰ìƒ ì„¤ì •
        color = (0, 255, 0) if emotion == "Happy" else (0, 0, 255) if emotion in ["Angry", "Sad"] else (255, 255, 0)

        # ì–¼êµ´ ì˜ì—­ì— ê°ì • í…ìŠ¤íŠ¸ í‘œì‹œ
        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
        cv2.putText(frame, emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

    return frame

# ì›¹ìº  ì‹¤í–‰ ë¡œì§
if st.session_state["webcam_active"]:
    video_capture = cv2.VideoCapture(0)

    if not video_capture.isOpened():
        st.error("ì›¹ìº ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.session_state["webcam_active"] = False
    else:
        stframe = st.image([])
        while st.session_state["webcam_active"]:
            ret, frame = video_capture.read()
            if not ret:
                st.error("ì›¹ìº  í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.session_state["webcam_active"] = False
                break

            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            if not st.session_state["webcam_active"]:  # ì˜ˆì¸¡ ì „ì— ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸
                break

            frame = detect_emotion(frame)

            # ì‹¤ì‹œê°„ í™”ë©´ ì—…ë°ì´íŠ¸
            stframe.image(frame, channels="RGB", use_container_width=True)

            time.sleep(0.1)  # CPU ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ì•½ê°„ì˜ ë”œë ˆì´ ì¶”ê°€

        # ì›¹ìº  ì¢…ë£Œ ì²˜ë¦¬
        video_capture.release()
        st.success("ì›¹ìº ì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
